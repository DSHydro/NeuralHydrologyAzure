{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f6c7445",
   "metadata": {},
   "source": [
    "This notebook substitutes the CARAVAN precipitation data with CHIRPS precipitation for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f585c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4564e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKUP_DIR = Path(\"../preparing_data/filtered_data/time_series\")\n",
    "DATA_DIR   = Path(\"./filtered_data_CHIRPS/time_series\")\n",
    "UYPRECIP_DIR = Path(\"./precip_timeseries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f959758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMELS_UY_7\n",
      "\n",
      "Processing basin: CAMELS_UY_7\n",
      "  ✔ Replacing precipitation for 11322 days\n",
      "CAMELS_UY_2\n",
      "\n",
      "Processing basin: CAMELS_UY_2\n",
      "  ✔ Replacing precipitation for 11322 days\n",
      "CAMELS_UY_16\n",
      "\n",
      "Processing basin: CAMELS_UY_16\n",
      "  ✔ Replacing precipitation for 11322 days\n",
      "CAMELS_UY_9\n",
      "\n",
      "Processing basin: CAMELS_UY_9\n",
      "  ✔ Replacing precipitation for 11322 days\n",
      "CAMELS_UY_5\n",
      "\n",
      "Processing basin: CAMELS_UY_5\n",
      "  ✔ Replacing precipitation for 11322 days\n",
      "CAMELS_UY_11\n",
      "\n",
      "Processing basin: CAMELS_UY_11\n",
      "  ✔ Replacing precipitation for 11322 days\n",
      "CAMELS_UY_6\n",
      "\n",
      "Processing basin: CAMELS_UY_6\n",
      "  ✔ Replacing precipitation for 11322 days\n",
      "CAMELS_UY_8\n",
      "\n",
      "Processing basin: CAMELS_UY_8\n",
      "  ✔ Replacing precipitation for 11322 days\n",
      "CAMELS_UY_3\n",
      "\n",
      "Processing basin: CAMELS_UY_3\n",
      "  ✔ Replacing precipitation for 11322 days\n",
      "CAMELS_UY_15\n",
      "\n",
      "Processing basin: CAMELS_UY_15\n",
      "  ✔ Replacing precipitation for 11322 days\n",
      "CAMELS_UY_10\n",
      "\n",
      "Processing basin: CAMELS_UY_10\n",
      "  ✔ Replacing precipitation for 11322 days\n",
      "\n",
      "✅ All basins processed successfully.\n"
     ]
    }
   ],
   "source": [
    "PRECIP_VAR = \"prcp_mm_day\"\n",
    "TIME_VAR = \"date\"\n",
    "\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for nc_in in BACKUP_DIR.glob(\"CAMELS_UY_*.nc\"):\n",
    "    basin_id = nc_in.stem\n",
    "    print(basin_id)\n",
    "    nc_out = DATA_DIR / nc_in.name\n",
    "    csv_file = UYPRECIP_DIR / f\"{basin_id}_precip.csv\"\n",
    "\n",
    "    print(f\"\\nProcessing basin: {basin_id}\")\n",
    "\n",
    "    # ---------- Load forcing ----------\n",
    "    ds = xr.open_dataset(nc_in).load()\n",
    "\n",
    "    if PRECIP_VAR not in ds or TIME_VAR not in ds.coords:\n",
    "        print(\"  ⏭ Missing precip or time coord – copying unchanged\")\n",
    "        ds.to_netcdf(nc_out)\n",
    "        ds.close()\n",
    "        continue\n",
    "\n",
    "    # ---------- Load gauge ----------\n",
    "    if not csv_file.exists():\n",
    "        print(\"  ⏭ No gauge data\")\n",
    "        # ds.to_netcdf(nc_out)\n",
    "        # ds.close()\n",
    "        continue\n",
    "\n",
    "    # df_gauge = (\n",
    "    #     pd.read_csv(csv_file, parse_dates=[TIME_VAR])\n",
    "    #     .set_index(TIME_VAR)\n",
    "    # )\n",
    "\n",
    "    df_gauge = (\n",
    "        pd.read_csv(csv_file, parse_dates=[\"time\"])\n",
    "        .rename(columns={\"time\": TIME_VAR})\n",
    "        .set_index(TIME_VAR)\n",
    "    )\n",
    "\n",
    "    # if \"precip_mm\" not in df_gauge.columns:\n",
    "    #     print(\"  ⏭ precip_mm missing – copying unchanged\")\n",
    "    #     ds.to_netcdf(nc_out)\n",
    "    #     ds.close()\n",
    "    #     continue\n",
    "\n",
    "    # ---------- Align dates ----------\n",
    "    ds_time = pd.to_datetime(ds[TIME_VAR].values)\n",
    "    common_dates = ds_time.intersection(df_gauge.index)\n",
    "\n",
    "    if len(common_dates) == 0:\n",
    "        print(\"  ⏭ No overlapping dates\")\n",
    "        # ds.to_netcdf(nc_out)\n",
    "        # ds.close()\n",
    "        continue\n",
    "\n",
    "    print(f\"  ✔ Replacing precipitation for {len(common_dates)} days\")\n",
    "\n",
    "    # ---------- Replace ----------\n",
    "    precip = ds[PRECIP_VAR].copy()\n",
    "    precip.loc[{TIME_VAR: common_dates}] = (\n",
    "        df_gauge.loc[common_dates, \"precipitation\"].values\n",
    "    )\n",
    "    # precip.attrs[\"source\"] = \"Gauge (INUMET)\"\n",
    "    ds[PRECIP_VAR] = precip\n",
    "\n",
    "    ds.attrs[\"precip_update\"] = \"Gauge data used where available\"\n",
    "\n",
    "    # ---------- Write ----------\n",
    "    ds.to_netcdf(nc_out)\n",
    "    ds.close()\n",
    "\n",
    "print(\"\\n✅ All basins processed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralhydrology",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
