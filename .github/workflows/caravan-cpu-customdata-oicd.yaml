name: NeuralHydrology OICD (CARAVAN)

permissions:
  id-token: write
  contents: read

on:
  workflow_dispatch:
    inputs:
      zipped_data_blob:
        description: 'blob name in Azure Storage'
        required: true
        type: string
        default: 'basin_timeseries_v1p2_metForcing_obsFlow.zip'
      runner_type:
        description: 'Select the runner type'
        required: true
        default: 'ubuntu-4core'
        type: choice
        options:
          - ubuntu-4core
          - ubuntu-8core
          - ubuntu-16core

jobs:
  train:
    environment: AIForGood
    runs-on: ${{ github.event.inputs.runner_type }}

    steps:
      - uses: actions/checkout@v5

      - name: AZ CLI login
        uses: azure/login@v2.3.0
        with:
          # NOTE: allow-no-subscripts needed if only giving scoped permissions to specific container
          allow-no-subscriptions: true
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}

      - name: Report Runner Specs
        run: |
          lscpu
          free -h
          df -h

      - uses: prefix-dev/setup-pixi@v0.9.2
        with:
            manifest-path: caravan_pyproject.toml
            cache: true
            frozen: true

      # TODO: scope cache key with workflow name? otherwise can end up with incorrect data
      # - name: Cache Data
      #   uses: actions/cache@v4
      #   with:
      #       path: input-data.zip
      #       key: ${{ runner.os }}-input-data

      - name: Download Data from Azure Blob Storage
        run: |
            az storage blob download \
                --no-progress \
                --auth-mode login \
                --account-name dshydro\
                --container-name accelerator2025 \
                --name ${{ github.event.inputs.zipped_data_blob }} \
                --file input-data.zip > /dev/null

      - name: Setup Tutorial Data
        run: |
            unzip -q -n input-data.zip -d ./data/
            mv ./data/basin_dataset_public_v1p2 ./data/CAMELS_US/

      - name: Run Training
        id: train
        run: |
            pixi run train-cpu
            OUTDIR=`ls runs/`
            echo "outdir=$OUTDIR" >> $GITHUB_OUTPUT

      - name: Run Evaluation
        run: |
            pixi run eval --run-dir ./runs/${{ steps.train.outputs.outdir }}

      - name: Visualize Results
        run: |
            pixi run visualize ./runs/${{ steps.train.outputs.outdir }}

      - name: Upload Results
        uses: actions/upload-artifact@v4
        with:
            name: ${{ steps.train.outputs.outdir }}
            path: ./runs/${{ steps.train.outputs.outdir }}
