{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import yaml\n",
    "import geopandas as gpd\n",
    "import contextily as cx\n",
    "from adjustText import adjust_text\n",
    "\n",
    "from neuralhydrology.nh_run import start_run, eval_run, finetune\n",
    "from neuralhydrology.nh_run import continue_run\n",
    "from neuralhydrology.utils.config import Config\n",
    "from neuralhydrology.evaluation import get_tester, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Paths ---------\n",
    "CONFIG_PATH = Path(\"./basins_excluded.yml\")\n",
    "RUNS_DIR = Path(\"runs\")\n",
    "PLOTS_DIR = Path(\"./evaluation_plots\")\n",
    "RUNS_DIR = Path(\"runs\")\n",
    "PLOTS_DIR = Path(\"evaluation_plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-20 22:24:19,057: Logging to /home/azureuser/sky_workdir/uy_precip_caravan_vs_gauge/runs/camels_uy_6_30_epochs_seq_270_hidden_256_dropout_04_fb_05_seed111_2001_222419/output.log initialized.\n",
      "2026-01-20 22:24:19,058: ### Folder structure created at /home/azureuser/sky_workdir/uy_precip_caravan_vs_gauge/runs/camels_uy_6_30_epochs_seq_270_hidden_256_dropout_04_fb_05_seed111_2001_222419\n",
      "2026-01-20 22:24:19,058: ### Run configurations for camels_uy_6_30_epochs_seq_270_hidden_256_dropout_04_fb_05_seed111\n",
      "2026-01-20 22:24:19,059: experiment_name: camels_uy_6_30_epochs_seq_270_hidden_256_dropout_04_fb_05_seed111\n",
      "2026-01-20 22:24:19,059: run_dir: /home/azureuser/sky_workdir/uy_precip_caravan_vs_gauge/runs/camels_uy_6_30_epochs_seq_270_hidden_256_dropout_04_fb_05_seed111_2001_222419\n",
      "2026-01-20 22:24:19,060: train_basin_file: camels_uy_6.txt\n",
      "2026-01-20 22:24:19,060: validation_basin_file: camels_uy_6.txt\n",
      "2026-01-20 22:24:19,061: test_basin_file: camels_uy_6.txt\n",
      "2026-01-20 22:24:19,061: train_start_date: 1999-10-01 00:00:00\n",
      "2026-01-20 22:24:19,062: train_end_date: 2008-09-30 00:00:00\n",
      "2026-01-20 22:24:19,062: validation_start_date: 1989-10-01 00:00:00\n",
      "2026-01-20 22:24:19,063: validation_end_date: 1999-09-30 00:00:00\n",
      "2026-01-20 22:24:19,063: seed: 111\n",
      "2026-01-20 22:24:19,064: device: cuda:0\n",
      "2026-01-20 22:24:19,064: validate_every: 1\n",
      "2026-01-20 22:24:19,065: metrics: ['NSE', 'KGE', 'Alpha-NSE', 'Beta-NSE', 'Pearson-r', 'RMSE', 'MSE', 'Beta-KGE']\n",
      "2026-01-20 22:24:19,065: model: cudalstm\n",
      "2026-01-20 22:24:19,066: head: regression\n",
      "2026-01-20 22:24:19,069: hidden_size: 256\n",
      "2026-01-20 22:24:19,070: initial_forget_bias: 5\n",
      "2026-01-20 22:24:19,072: output_dropout: 0.4\n",
      "2026-01-20 22:24:19,072: output_activation: linear\n",
      "2026-01-20 22:24:19,073: optimizer: Adam\n",
      "2026-01-20 22:24:19,073: loss: NSE\n",
      "2026-01-20 22:24:19,074: learning_rate: {0: 0.001}\n",
      "2026-01-20 22:24:19,074: batch_size: 256\n",
      "2026-01-20 22:24:19,076: epochs: 30\n",
      "2026-01-20 22:24:19,077: clip_gradient_norm: 1\n",
      "2026-01-20 22:24:19,077: predict_last_n: 1\n",
      "2026-01-20 22:24:19,078: seq_length: 270\n",
      "2026-01-20 22:24:19,078: num_workers: 4\n",
      "2026-01-20 22:24:19,079: log_interval: 5\n",
      "2026-01-20 22:24:19,079: log_tensorboard: True\n",
      "2026-01-20 22:24:19,080: save_weights_every: 1\n",
      "2026-01-20 22:24:19,080: save_validation_results: True\n",
      "2026-01-20 22:24:19,081: data_dir: /home/azureuser/sky_workdir/preparing_data/filtered_data_gauge_precip\n",
      "2026-01-20 22:24:19,082: dataset: generic\n",
      "2026-01-20 22:24:19,082: dynamic_inputs: ['prcp_mm_day', 'srad_W_m2', 'tmax_C', 'tmin_C']\n",
      "2026-01-20 22:24:19,082: target_variables: ['QObs_mm_d']\n",
      "2026-01-20 22:24:19,083: static_attributes: ['elev_mean', 'slope_mean', 'area_gages2', 'sand_frac', 'silt_frac', 'clay_frac', 'p_mean', 'pet_mean', 'aridity', 'high_prec_dur', 'low_prec_dur']\n",
      "2026-01-20 22:24:19,083: number_of_basins: 1\n",
      "2026-01-20 22:24:19,084: train_dir: /home/azureuser/sky_workdir/uy_precip_caravan_vs_gauge/runs/camels_uy_6_30_epochs_seq_270_hidden_256_dropout_04_fb_05_seed111_2001_222419/train_data\n",
      "2026-01-20 22:24:19,084: img_log_dir: /home/azureuser/sky_workdir/uy_precip_caravan_vs_gauge/runs/camels_uy_6_30_epochs_seq_270_hidden_256_dropout_04_fb_05_seed111_2001_222419/img_log\n",
      "2026-01-20 22:24:19,086: ### Device cuda:0 will be used for training\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The following attributes have a std of zero or NaN, which results in NaN's when normalizing the features. Remove the attributes from the attribute feature list and restart the run. \nAttributes: ['elev_mean', 'slope_mean', 'area_gages2', 'sand_frac', 'silt_frac', 'clay_frac', 'p_mean', 'pet_mean', 'aridity', 'high_prec_dur', 'low_prec_dur']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# by default we assume that you have at least one CUDA-capable NVIDIA GPU or MacOS with Metal support\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muy_gauge.yml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# fall back to CPU-only mode\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     start_run(config_file\u001b[38;5;241m=\u001b[39mPath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muy_gauge.yml\u001b[39m\u001b[38;5;124m\"\u001b[39m), gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/neuralhydrology/lib/python3.10/site-packages/neuralhydrology/nh_run.py:77\u001b[0m, in \u001b[0;36mstart_run\u001b[0;34m(config_file, gpu)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gpu \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gpu \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     75\u001b[0m     config\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 77\u001b[0m \u001b[43mstart_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/neuralhydrology/lib/python3.10/site-packages/neuralhydrology/training/train.py:19\u001b[0m, in \u001b[0;36mstart_training\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown head \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mhead\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain_and_validate()\n",
      "File \u001b[0;32m~/miniconda3/envs/neuralhydrology/lib/python3.10/site-packages/neuralhydrology/training/basetrainer.py:147\u001b[0m, in \u001b[0;36mBaseTrainer.initialize_training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scaler \u001b[38;5;241m=\u001b[39m load_scaler(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mbase_run_dir)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Initialize dataset before the model is loaded.\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ds) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset contains no samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/neuralhydrology/lib/python3.10/site-packages/neuralhydrology/training/basetrainer.py:80\u001b[0m, in \u001b[0;36mBaseTrainer._get_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_dataset\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseDataset:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scaler\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/neuralhydrology/lib/python3.10/site-packages/neuralhydrology/datasetzoo/__init__.py:83\u001b[0m, in \u001b[0;36mget_dataset\u001b[0;34m(cfg, is_train, period, basin, additional_features, id_to_int, scaler)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo dataset class implemented for dataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 83\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m             \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m             \u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperiod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m             \u001b[49m\u001b[43mbasin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbasin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m             \u001b[49m\u001b[43madditional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m             \u001b[49m\u001b[43mid_to_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_to_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m             \u001b[49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/miniconda3/envs/neuralhydrology/lib/python3.10/site-packages/neuralhydrology/datasetzoo/genericdataset.py:61\u001b[0m, in \u001b[0;36mGenericDataset.__init__\u001b[0;34m(self, cfg, is_train, period, basin, additional_features, id_to_int, scaler)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     54\u001b[0m              cfg: Config,\n\u001b[1;32m     55\u001b[0m              is_train: \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m              id_to_int: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m {},\n\u001b[1;32m     60\u001b[0m              scaler: Dict[\u001b[38;5;28mstr\u001b[39m, Union[pd\u001b[38;5;241m.\u001b[39mSeries, xarray\u001b[38;5;241m.\u001b[39mDataArray]] \u001b[38;5;241m=\u001b[39m {}):\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mGenericDataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperiod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mbasin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbasin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43madditional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mid_to_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_to_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/neuralhydrology/lib/python3.10/site-packages/neuralhydrology/datasetzoo/basedataset.py:142\u001b[0m, in \u001b[0;36mBaseDataset.__init__\u001b[0;34m(self, cfg, is_train, period, basin, additional_features, id_to_int, scaler)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_id_to_int()\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# load and preprocess data\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_train:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dump_scaler()\n",
      "File \u001b[0;32m~/miniconda3/envs/neuralhydrology/lib/python3.10/site-packages/neuralhydrology/datasetzoo/basedataset.py:745\u001b[0m, in \u001b[0;36mBaseDataset._load_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_load_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# load attributes first to sanity-check those features before doing the compute expensive time series loading\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_combined_attributes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m     xr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_or_create_xarray_dataset()\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweightednse\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    750\u001b[0m         \u001b[38;5;66;03m# get the std of the discharge for each basin, which is needed for the (weighted) NSE loss.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/neuralhydrology/lib/python3.10/site-packages/neuralhydrology/datasetzoo/basedataset.py:703\u001b[0m, in \u001b[0;36mBaseDataset._load_combined_attributes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;66;03m# in case of training (not finetuning) check for NaNs in feature std.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_scaler:\n\u001b[0;32m--> 703\u001b[0m         \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattributes_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m    707\u001b[0m \u001b[38;5;66;03m# Hydroatlas attributes can be used everywhere\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/neuralhydrology/lib/python3.10/site-packages/neuralhydrology/datautils/utils.py:174\u001b[0m, in \u001b[0;36mattributes_sanity_check\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attributes:\n\u001b[1;32m    169\u001b[0m     msg \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following attributes have a std of zero or NaN, which results in NaN\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen normalizing the features. Remove the attributes from the attribute feature list \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand restart the run. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttributes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattributes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m     ]\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(msg))\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# Check for NaNs in any attribute of any basin\u001b[39;00m\n\u001b[1;32m    177\u001b[0m nan_df \u001b[38;5;241m=\u001b[39m df[df\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39many(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following attributes have a std of zero or NaN, which results in NaN's when normalizing the features. Remove the attributes from the attribute feature list and restart the run. \nAttributes: ['elev_mean', 'slope_mean', 'area_gages2', 'sand_frac', 'silt_frac', 'clay_frac', 'p_mean', 'pet_mean', 'aridity', 'high_prec_dur', 'low_prec_dur']"
     ]
    }
   ],
   "source": [
    "# by default we assume that you have at least one CUDA-capable NVIDIA GPU or MacOS with Metal support\n",
    "if torch.cuda.is_available() or torch.backends.mps.is_available():\n",
    "    start_run(config_file=Path(\"uy_gauge.yml\"))\n",
    "\n",
    "# fall back to CPU-only mode\n",
    "else:\n",
    "    start_run(config_file=Path(\"uy_gauge.yml\"), gpu=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralhydrology",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
